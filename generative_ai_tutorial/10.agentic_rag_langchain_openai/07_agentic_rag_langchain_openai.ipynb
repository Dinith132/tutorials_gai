{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ueui7jbkeGet"
      },
      "source": [
        "# **Agentic RAG** with LangChain and OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FvvBzKTL6f9",
        "outputId": "1f454b0a-94bb-4c35-f03b-c7e31af5256c"
      },
      "outputs": [],
      "source": [
        "# # Install the necessary packages\n",
        "# !pip install langchain -qU\n",
        "# !pip install langchain-openai -qU\n",
        "# !pip install langchain-community -qU\n",
        "# !pip install langchain-chroma -qU\n",
        "\n",
        "# !pip install duckduckgo-search -qU\n",
        "# !pip install pyowm -qU\n",
        "\n",
        "# !pip install langchainhub -qU\n",
        "\n",
        "# !pip install pypdf -qU\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_0hk8jC9MDjA"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyBcUsfH8V9z9ES0SVlYRAZAY_Lp2AdO800\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3H2D6t19eU6q"
      },
      "source": [
        "### Initialize OpenAI LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "JfdcEWGBQyk8"
      },
      "outputs": [],
      "source": [
        "from langchain_google_genai import GoogleGenerativeAI\n",
        "llm=GoogleGenerativeAI(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    temperature=0.1\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eevNQcSneq9M"
      },
      "source": [
        "### Initialize Embedding Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "R6VmxYgAQN9J"
      },
      "outputs": [],
      "source": [
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "\n",
        "embedding=GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFQ5Amu3ehGr"
      },
      "source": [
        "### Initialize DuckDuckGo Search Tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WI6BfiryYK3f",
        "outputId": "794467b9-6665-484f-d91d-e2e920e51183"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DuckDuckGoSearchRun(api_wrapper=DuckDuckGoSearchAPIWrapper(region='wt-wt', safesearch='moderate', time='y', max_results=5, backend='auto', source='text'))"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import time\n",
        "from langchain_community.tools import DuckDuckGoSearchRun\n",
        "\n",
        "search_tool= DuckDuckGoSearchRun()\n",
        "\n",
        "search_tool\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3S6k0U0JeziU"
      },
      "source": [
        "### Initialize OpenWeatherMap Tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjBynGG9YMBG",
        "outputId": "dadcd410-857b-4e3a-f420-787bac1dc84c"
      },
      "outputs": [],
      "source": [
        "from langchain_community.utilities import OpenWeatherMapAPIWrapper\n",
        "from langchain.agents import load_tools\n",
        "\n",
        "os.environ[\"OPENWEATHERMAP_API_KEY\"] = \"c34893b2274bb04db3ff96b6214986f6\"\n",
        "\n",
        "# Initialize OpenWeatherMap tool\n",
        "weather = OpenWeatherMapAPIWrapper()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "OpenWeatherMapQueryRun(api_wrapper=OpenWeatherMapAPIWrapper(owm=<pyowm.owm.OWM - API key=************************214986f6, subscription type=free, PyOWM version=(3, 3, 0)>, openweathermap_api_key=None))"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "weather_tool = load_tools([\"openweathermap-api\"], llm)[0]\n",
        "\n",
        "weather_tool"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teoVYsQoe3cL"
      },
      "source": [
        "### Initialize RAG Tool"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uhSKNjLe8-j"
      },
      "source": [
        "##### Load PDF Document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uvn66tl_QwdJ",
        "outputId": "9b8695b6-e4ee-4736-b3b2-7bcef933d5bd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "o0wQ0FW2Q5NY"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "# Load the PDF document\n",
        "loader = PyPDFLoader(\"codeprolk.pdf\")\n",
        "\n",
        "docs = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iinTw94OQ754",
        "outputId": "fa9a671e-3c8b-4296-a00c-af86bc269c29"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-eC8l9EfQ5E"
      },
      "source": [
        "##### Split Documents into Chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "iyF5Ro59Q94F"
      },
      "outputs": [],
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "# Initialize the text splitter\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=400, chunk_overlap=50)\n",
        "\n",
        "# Split the documents into chunks\n",
        "splits = text_splitter.split_documents(docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_Y4HzulfYji"
      },
      "source": [
        "##### Create Vector Store and Retriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\dinit\\.pyenv\\pyenv-win\\versions\\3.11.5\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "13eefbcb0d224895b0d70c31b245279e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\dinit\\.pyenv\\pyenv-win\\versions\\3.11.5\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\dinit\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
            "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
            "  warnings.warn(message)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1e833a18f1b0423892806979bbb7bdea",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8ab6fc572ec146f298e97c011ce5144a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "54303887a03c4829a8df9e7780a58818",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7ae4dc8b4dc04e01bd1c7c0450c79f57",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d94d2df1277c422e83cd3c5d49a198d9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6cdba002629b4c37a77a53c9eac035d6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "642a31fe80554e0193cdc7c83a232d01",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dbe34a0d06ad469ba8d6b6f37ef244b9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6e54b1e584f44ad6a0d8aac2d803cacd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c0bb47adcbc94493adb0461aa884cd2e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "embedding = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ghSmPlIHRBe4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
            "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        }
      ],
      "source": [
        "from langchain_chroma import Chroma\n",
        "\n",
        "# Create a vector store from the document chunks\n",
        "vectorstore = Chroma.from_documents(documents=splits, embedding=embedding)\n",
        "\n",
        "# Create a retriever from the vector store\n",
        "retriever = vectorstore.as_retriever()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8Rqg0iSfso6"
      },
      "source": [
        "##### Create Retrieval-Augmented Generation (RAG) Chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ybUfo4NVRIFE"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "# Retrieval qa chain\n",
        "rag_chain = RetrievalQA.from_chain_type(\n",
        "                                    llm=llm,\n",
        "                                    chain_type=\"stuff\",\n",
        "                                    retriever=retriever)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "o06xmiv6YZje"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import Tool\n",
        "\n",
        "rag_tool = Tool(\"RAG tool\",\n",
        "              func = rag_chain.run,\n",
        "              description = \"Use it to lookup information from the Veector Store\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bknz7x-IgEAz"
      },
      "source": [
        "### Define Prompt Template"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5ye7KpKSJoc",
        "outputId": "e7b2bd11-c686-48e6-ac71-e4a9062fb4b9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\dinit\\.pyenv\\pyenv-win\\versions\\3.11.5\\Lib\\site-packages\\langsmith\\client.py:272: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from langchain import hub\n",
        "prompt = hub.pull(\"hwchase17/react\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Answer the following questions as best you can. You have access to the following tools:\n",
            "\n",
            "{tools}\n",
            "\n",
            "Use the following format:\n",
            "\n",
            "Question: the input question you must answer\n",
            "Thought: you should always think about what to do\n",
            "Action: the action to take, should be one of [{tool_names}]\n",
            "Action Input: the input to the action\n",
            "Observation: the result of the action\n",
            "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
            "Thought: I now know the final answer\n",
            "Final Answer: the final answer to the original input question\n",
            "\n",
            "Begin!\n",
            "\n",
            "Question: {input}\n",
            "Thought:{agent_scratchpad}\n"
          ]
        }
      ],
      "source": [
        "print(prompt.template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "GfCYtU6jSWna"
      },
      "outputs": [],
      "source": [
        "# Set prompt template\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "template= '''\n",
        "          Answer the following questions as best you can. You have access to the following tools:\n",
        "\n",
        "          {tools}\n",
        "\n",
        "          Use the following format:\n",
        "\n",
        "          Question: the input question you must answer\n",
        "          Thought: you should always think about what to do\n",
        "          Action: the action to take, should be one of [{tool_names}]. Always look first in Vector Store\n",
        "          Action Input: the input to the action\n",
        "          Observation: the result of the action\n",
        "          ... (this Thought/Action/Action Input/Observation can repeat 2 times)\n",
        "          Thought: I now know the final answer\n",
        "          Final Answer: the final answer to the original input question\n",
        "\n",
        "          Begin!\n",
        "\n",
        "          Question: {input}\n",
        "          Thought:{agent_scratchpad}\n",
        "          '''\n",
        "\n",
        "prompt = PromptTemplate.from_template(template)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3yQVbvhgeES"
      },
      "source": [
        "### Create Built-in Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Hn21xnDjY4T_"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import create_react_agent\n",
        "\n",
        "# List of tools for the agent\n",
        "tools = [search_tool, rag_tool, weather_tool]\n",
        "\n",
        "# Create the agent using the LLM and the prompt template\n",
        "agent = create_react_agent(tools = tools, llm = llm, prompt=prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "YRhya9gmSltO"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import AgentExecutor\n",
        "\n",
        "# Initialize the agent executor with the created agent and tools\n",
        "agent_executor = AgentExecutor(tools=tools, agent=agent, handle_parsing_errors=True, verbose=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LinaH7_sgogb"
      },
      "source": [
        "### Invoke the agent executor with an example question"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJfQrpTjS6EM",
        "outputId": "d43faf93-e4b5-4aa4-92df-8cf2fc214584"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Failed to send telemetry event CollectionQueryEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32;1m\u001b[1;3mAction: RAG tool\n",
            "Action Input: courses in codeprolk\u001b[0m\u001b[33;1m\u001b[1;3mCodePRO LK offers a wide array of free, technology-related courses, all presented in Sinhala. These courses cater to various proficiency levels, from beginners to intermediates, covering areas like programming, data science, and machine learning.\n",
            "\n",
            "A key course mentioned is:\n",
            "*   **Python GUI – Tkinter:** Covers the essentials of creating graphical user interfaces.\n",
            "\n",
            "Looking ahead, CodePRO LK aims to expand its course offerings to cover more advanced topics and emerging technologies, including areas like artificial intelligence, cybersecurity, and advanced data analytics.\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer\n",
            "Final Answer: CodePRO LK offers a wide array of free, technology-related courses in Sinhala, suitable for beginners to intermediates. These courses cover areas such as programming, data science, and machine learning. A specific course mentioned is \"Python GUI – Tkinter,\" which teaches how to create graphical user interfaces. CodePRO LK plans to expand its offerings to include advanced topics like artificial intelligence, cybersecurity, and advanced data analytics.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "CodePRO LK offers a wide array of free, technology-related courses in Sinhala, suitable for beginners to intermediates. These courses cover areas such as programming, data science, and machine learning. A specific course mentioned is \"Python GUI – Tkinter,\" which teaches how to create graphical user interfaces. CodePRO LK plans to expand its offerings to include advanced topics like artificial intelligence, cybersecurity, and advanced data analytics.\n"
          ]
        }
      ],
      "source": [
        "response = agent_executor.invoke({\"input\":\"courses in codeprolk\"})\n",
        "\n",
        "print(response['output'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s57Ur3C3Tb1A",
        "outputId": "d8f59c7d-ea7a-4543-bf6a-41fb0a35cd0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mAction: RAG tool\n",
            "Action Input: president of Sri Lanka\u001b[0m\u001b[33;1m\u001b[1;3mI don't know. The provided context does not contain information about the president of Sri Lanka.\u001b[0m\u001b[32;1m\u001b[1;3mAction: duckduckgo_search\n",
            "Action Input: president of Sri Lanka\u001b[0m\u001b[36;1m\u001b[1;3mAnura Kumara Dissanayake is the current president of Sri Lanka since 2024, elected from the National People's Power party. He is a former leader of the JVP and a former student activist who participated in the 1987 insurrection. Left-leaning politician Anura Kumara Dissanayake has been elected as Sri Lanka's next president after he won the debt-ridden country's first election since its economy collapsed in 2022. The ... Marxist lawmaker Anura Kumara Dissanayake, whose pro-working class and anti-political elite campaigning made him popular among youth, won Sri Lanka's presidential election, the Election ... Marxist-leaning politician Anura Kumara Dissanayake has taken his oath as Sri Lanka's new president after he was declared the winner of Saturday's election. Dissanayake took his oath at the ... Two years after a seismic political and economic crisis rocked Sri Lanka and brought citizens to the streets in mass protests movements that ousted President Gotabaya Rajapaksa, Sri Lanka's citizens went to the polls to cast their votes for a new president. On September 21, Sri Lankans elected the left-leaning Anura Kumara Dissanayake over established politicians including incumbent ...\u001b[0m\u001b[32;1m\u001b[1;3mFinal Answer: Anura Kumara Dissanayake is the current president of Sri Lanka.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Anura Kumara Dissanayake is the current president of Sri Lanka.\n"
          ]
        }
      ],
      "source": [
        "response = agent_executor.invoke({\"input\": \"who is presiden of Sri Lanka?\"})\n",
        "\n",
        "print(response['output'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mAction: open_weather_map\n",
            "Action Input: Colombo,LK\u001b[0m\u001b[38;5;200m\u001b[1;3mIn Colombo,LK, the current weather is as follows:\n",
            "Detailed status: overcast clouds\n",
            "Wind speed: 4.75 m/s, direction: 231°\n",
            "Humidity: 87%\n",
            "Temperature: \n",
            "  - Current: 26.92°C\n",
            "  - High: 26.92°C\n",
            "  - Low: 26.92°C\n",
            "  - Feels like: 30.21°C\n",
            "Rain: {}\n",
            "Heat index: None\n",
            "Cloud cover: 89%\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer\n",
            "Final Answer: The current weather in Colombo, Sri Lanka is overcast clouds with a temperature of 26.92°C, feeling like 30.21°C. The wind speed is 4.75 m/s from 231°, and humidity is 87%. Cloud cover is 89%.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "The current weather in Colombo, Sri Lanka is overcast clouds with a temperature of 26.92°C, feeling like 30.21°C. The wind speed is 4.75 m/s from 231°, and humidity is 87%. Cloud cover is 89%.\n"
          ]
        }
      ],
      "source": [
        "response = agent_executor.invoke({\"input\": \"give me the weather in Colombo\"})\n",
        "\n",
        "print(response['output'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.agents import tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[DuckDuckGoSearchRun(api_wrapper=DuckDuckGoSearchAPIWrapper(region='wt-wt', safesearch='moderate', time='y', max_results=5, backend='auto', source='text')),\n",
              " Tool(name='RAG tool', description='Use it to lookup information from the Veector Store', func=<bound method Chain.run of RetrievalQA(verbose=False, combine_documents_chain=StuffDocumentsChain(verbose=False, llm_chain=LLMChain(verbose=False, prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\\n\\n{context}\\n\\nQuestion: {question}\\nHelpful Answer:\"), llm=GoogleGenerativeAI(model='gemini-2.5-flash', google_api_key=SecretStr('**********'), temperature=0.1, client=ChatGoogleGenerativeAI(model='models/gemini-2.5-flash', google_api_key=SecretStr('**********'), temperature=0.1, client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x00000191AFAF7E90>, default_metadata=(), model_kwargs={})), output_parser=StrOutputParser(), llm_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_variable_name='context'), retriever=VectorStoreRetriever(tags=['Chroma', 'HuggingFaceEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x00000191EE9EAD90>, search_kwargs={}))>),\n",
              " OpenWeatherMapQueryRun(api_wrapper=OpenWeatherMapAPIWrapper(owm=<pyowm.owm.OWM - API key=************************214986f6, subscription type=free, PyOWM version=(3, 3, 0)>, openweathermap_api_key=None))]"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "@tool\n",
        "def word_count(text: str) -> int:\n",
        "    \"\"\"Return the word count.\"\"\"\n",
        "    return len(text.split())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "tools.append(word_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[DuckDuckGoSearchRun(api_wrapper=DuckDuckGoSearchAPIWrapper(region='wt-wt', safesearch='moderate', time='y', max_results=5, backend='auto', source='text')),\n",
              " Tool(name='RAG tool', description='Use it to lookup information from the Veector Store', func=<bound method Chain.run of RetrievalQA(verbose=False, combine_documents_chain=StuffDocumentsChain(verbose=False, llm_chain=LLMChain(verbose=False, prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\\n\\n{context}\\n\\nQuestion: {question}\\nHelpful Answer:\"), llm=GoogleGenerativeAI(model='gemini-2.5-flash', google_api_key=SecretStr('**********'), temperature=0.1, client=ChatGoogleGenerativeAI(model='models/gemini-2.5-flash', google_api_key=SecretStr('**********'), temperature=0.1, client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x00000191AFAF7E90>, default_metadata=(), model_kwargs={})), output_parser=StrOutputParser(), llm_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_variable_name='context'), retriever=VectorStoreRetriever(tags=['Chroma', 'HuggingFaceEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x00000191EE9EAD90>, search_kwargs={}))>),\n",
              " OpenWeatherMapQueryRun(api_wrapper=OpenWeatherMapAPIWrapper(owm=<pyowm.owm.OWM - API key=************************214986f6, subscription type=free, PyOWM version=(3, 3, 0)>, openweathermap_api_key=None)),\n",
              " StructuredTool(name='word_count', description='Return the word count.', args_schema=<class 'langchain_core.utils.pydantic.word_count'>, func=<function word_count at 0x00000191F329DF80>)]"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "agent= create_react_agent(tools = tools, llm = llm, prompt=prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "agent_executor = AgentExecutor(tools=tools, agent=agent, handle_parsing_errors=True, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mAction: RAG tool\n",
            "Action Input: codepro\u001b[0m\u001b[33;1m\u001b[1;3mHelpful Answer: CodePRO LK is a dynamic educational platform founded by Dinesh Piyasamara during the COVID-19 pandemic. It offers a diverse range of high-quality technology-related courses in Sinhala, including programming, data science, and machine learning, with plans to expand into areas like artificial intelligence, cybersecurity, and advanced data analytics. Its aim is to empower Sri Lankans with valuable tech skills, and it also maintains a vibrant community and a YouTube channel.\u001b[0m\u001b[32;1m\u001b[1;3mFinal Answer: CodePRO LK is a dynamic educational platform founded by Dinesh Piyasamara during the COVID-19 pandemic. It offers a diverse range of high-quality technology-related courses in Sinhala, including programming, data science, and machine learning, with plans to expand into areas like artificial intelligence, cybersecurity, and advanced data analytics. Its aim is to empower Sri Lankans with valuable tech skills, and it also maintains a vibrant community and a YouTube channel.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "response=agent_executor.invoke({\"input\":\"who is codepro?\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'CodePRO LK is a dynamic educational platform founded by Dinesh Piyasamara during the COVID-19 pandemic. It offers a diverse range of high-quality technology-related courses in Sinhala, including programming, data science, and machine learning, with plans to expand into areas like artificial intelligence, cybersecurity, and advanced data analytics. Its aim is to empower Sri Lankans with valuable tech skills, and it also maintains a vibrant community and a YouTube channel.'"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response['output']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mAction: word_count\n",
            "Action Input: what is game of thrones?\u001b[0m\u001b[36;1m\u001b[1;3m5\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer\n",
            "Final Answer: 5\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "response=agent_executor.invoke({\"input\":\"what is the word count for what is game of thrones?\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'5'"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response['output']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mAction: duckduckgo_search\n",
            "Action Input: where is the Eiffel Tower located\u001b[0m\u001b[36;1m\u001b[1;3mEiffel Tower, wrought-iron structure in Paris that is one of the most famous landmarks in the world. It is also a technological masterpiece in building-construction history. It was designed and built (1887-89) by Gustave Eiffel and named in his honor. The Eiffel Tower, located in the 7th arrondissement of Paris, sees nearly 7 million visitors yearly, according to the Office du Tourisme de Paris. According to a survey by the City of Paris, the 7th arrondissement scored a 92/100 satisfaction rating for architectural interest among residents and tourists in 2020. The Eiffel Tower is in Paris, France, on the Champ de Mars near the Seine River. Learn about its history, height, structure, observation decks, lighting and cultural significance. Learn how to get to the Eiffel Tower by public transport, metro, RER, bus, or boat. Find out the best spots to view the tower, the opening hours, ticket prices, and special events. Where is the Eiffel Tower located? The Eiffel Tower (or the Tour Eiffel in French) is located in the Champ de Mars, a big public park on the banks of the Seine River, in the 7th arrondissement of ...\u001b[0m\u001b[32;1m\u001b[1;3mAction: open_weather_map\n",
            "Action Input: Paris,FR\u001b[0m\u001b[38;5;200m\u001b[1;3mIn Paris,FR, the current weather is as follows:\n",
            "Detailed status: few clouds\n",
            "Wind speed: 2.16 m/s, direction: 284°\n",
            "Humidity: 26%\n",
            "Temperature: \n",
            "  - Current: 33.95°C\n",
            "  - High: 33.95°C\n",
            "  - Low: 33.95°C\n",
            "  - Feels like: 32.6°C\n",
            "Rain: {}\n",
            "Heat index: None\n",
            "Cloud cover: 23%\u001b[0m\u001b[32;1m\u001b[1;3mAction: word_count\n",
            "Action Input: In Paris,FR, the current weather is as follows:\n",
            "Detailed status: few clouds\n",
            "Wind speed: 2.16 m/s, direction: 284°\n",
            "Humidity: 26%\n",
            "Temperature: \n",
            "  - Current: 33.95°C\n",
            "  - High: 33.95°C\n",
            "  - Low: 33.95°C\n",
            "  - Feels like: 32.6°C\n",
            "Rain: {}\n",
            "Heat index: None\n",
            "Cloud cover: 23%\u001b[0m\u001b[36;1m\u001b[1;3m42\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer\n",
            "Final Answer: The Eiffel Tower is located in Paris, France. The current weather in Paris is few clouds, with a temperature of 33.95°C. The word count for the weather report is 42.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'The Eiffel Tower is located in Paris, France. The current weather in Paris is few clouds, with a temperature of 33.95°C. The word count for the weather report is 42.'"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response=agent_executor.invoke({\"input\":\"find where located ifeltower and find the weather there, then find the word count for the weather report.\"})\n",
        "response['output']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@tool\n",
        "def "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
