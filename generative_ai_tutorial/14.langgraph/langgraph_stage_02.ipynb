{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Q_3sSXTWr9F",
        "outputId": "4f2a86a7-c744-4fef-e04a-2944955850ae"
      },
      "outputs": [],
      "source": [
        "!pip install langchain==0.3.24 -q\n",
        "!pip install langchain-openai -q\n",
        "!pip install langgraph -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOoYhsIQXm-U"
      },
      "source": [
        "### Chat Agent + Conversational Chat Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "qffIR7HHWwql"
      },
      "outputs": [],
      "source": [
        "from typing import TypedDict, List\n",
        "from langchain_core.messages import HumanMessage\n",
        "# from langchain_openai import ChatOpenAI\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "\n",
        "from typing import TypedDict, List, Union\n",
        "from langchain_core.messages import HumanMessage, AIMessage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CoSkPeWtW4GD"
      },
      "outputs": [],
      "source": [
        "# class AgentState(TypedDict):\n",
        "#     messages: List[HumanMessage]\n",
        "\n",
        "    \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "import os\n",
        "from langchain_google_genai import GoogleGenerativeAI\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 202,
      "metadata": {
        "id": "A3fnXhZ8Xc6Z"
      },
      "outputs": [],
      "source": [
        "class AgentState(TypedDict):\n",
        "    messages: List[Union[HumanMessage, AIMessage]]\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyBcUsfH8V9z9ES0SVlYRAZAY_Lp2AdO800\"\n",
        "\n",
        "llm=GoogleGenerativeAI(\n",
        "    model=\"gemini-2.5-flash\", temperature=0.1\n",
        "    )\n",
        "embedding=GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
        "\n",
        "def chatbot(state: AgentState) -> AgentState:\n",
        "    response = llm.invoke(state[\"messages\"])\n",
        "    # state[\"messages\"].append(AIMessage(content=response.content))\n",
        "    state['messages'].append(AIMessage(content=response))\n",
        "    return state\n",
        "\n",
        "workflow = StateGraph(AgentState)\n",
        "\n",
        "workflow.add_node(\"chatbot\", chatbot)\n",
        "\n",
        "workflow.add_edge(START, \"chatbot\")\n",
        "workflow.add_edge(\"chatbot\", END)\n",
        "\n",
        "app = workflow.compile()\n",
        "\n",
        "# from IPython.display import Image, display\n",
        "# display(Image(app.get_graph().draw_mermaid_png()))\n",
        "\n",
        "# user_input = input(\"Enter a Query: \")\n",
        "# result = app.invoke({\"messages\": [HumanMessage(content=user_input)]})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'messages': [HumanMessage(content='hi', additional_kwargs={}, response_metadata={}),\n",
              "  AIMessage(content='Hello! How can I help you today?', additional_kwargs={}, response_metadata={})]}"
            ]
          },
          "execution_count": 191,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 204,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HmZD6QcJXhJ5",
        "outputId": "9ea3c2da-c9ca-4e0f-ee6a-03c5e9e5a636"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "You: can you explain what is the difference between langchain and graph?\n",
            "AI: That's an excellent question because while they are very different, they often complement each other in advanced AI applications.\n",
            "\n",
            "Let's break down LangChain and \"Graph\" (which I'll interpret as **Graph Databases** or **Knowledge Graphs**, as that's the most common context for this comparison).\n",
            "\n",
            "---\n",
            "\n",
            "### 1. LangChain: The Orchestration Framework for LLM Applications\n",
            "\n",
            "*   **What it is:** LangChain is an open-source **framework or library** designed to help developers build applications powered by Large Language Models (LLMs). It's not an LLM itself, nor is it a database.\n",
            "*   **What it does:** It provides tools and abstractions to:\n",
            "    *   **Chain together LLMs:** Combine multiple LLM calls or other components (like a search engine, a calculator, or a database query) into a sequence.\n",
            "    *   **Connect LLMs to external data:** Allow LLMs to interact with your own data sources (e.g., documents, databases, APIs) for retrieval-augmented generation (RAG).\n",
            "    *   **Enable LLMs to interact with their environment:** Give LLMs \"tools\" to perform actions (e.g., search the web, run code, query a database).\n",
            "    *   **Manage conversation history (Memory):** Keep track of past interactions to maintain context.\n",
            "    *   **Build Agents:** Create LLM-powered agents that can decide which actions to take based on user input.\n",
            "*   **Primary Goal:** To simplify the development of complex, context-aware, and interactive applications that leverage the power of LLMs. It's about **orchestration and application logic**.\n",
            "\n",
            "---\n",
            "\n",
            "### 2. Graph (Graph Databases / Knowledge Graphs): The Data Structure for Relationships\n",
            "\n",
            "*   **What it is:** A \"Graph\" in this context refers to a **data structure and a type of database** (a Graph Database) that stores data in terms of **nodes** (entities) and **edges** (relationships between those entities). A **Knowledge Graph** is a specific type of graph that represents real-world entities and their relationships in a structured, machine-readable format.\n",
            "*   **What it does:**\n",
            "    *   **Models complex relationships:** Excellent for representing highly interconnected data where the relationships themselves are as important as the data points (e.g., social networks, supply chains, biological pathways, organizational structures).\n",
            "    *   **Efficiently traverses connections:** Allows for very fast queries that involve navigating many relationships (e.g., \"Find all friends of friends who live in New York and work at Google\").\n",
            "    *   **Enables sophisticated reasoning:** By explicitly defining relationships, graphs can support complex inferencing and pattern discovery.\n",
            "    *   **Provides structured knowledge:** A knowledge graph acts as a structured repository of facts and their connections, making it easier for machines (and LLMs) to understand and reason about information.\n",
            "*   **Primary Goal:** To store, manage, and query highly interconnected data, emphasizing the relationships between data points. It's about **data representation and storage**.\n",
            "\n",
            "---\n",
            "\n",
            "### Key Differences Summarized:\n",
            "\n",
            "| Feature          | LangChain                                      | Graph (Database/Knowledge Graph)                 |\n",
            "| :--------------- | :--------------------------------------------- | :----------------------------------------------- |\n",
            "| **Category**     | LLM Application Framework / Orchestration Tool | Data Model / Database Type                       |\n",
            "| **Primary Role** | Building and running LLM-powered applications  | Storing and querying interconnected data         |\n",
            "| **Focus**        | Application logic, LLM interaction, workflows  | Relationships, entities, structured knowledge    |\n",
            "| **Components**   | Chains, Agents, Tools, Prompts, Memory         | Nodes, Edges, Properties                         |\n",
            "| **Output**       | LLM responses, actions, application flow       | Structured data, relationships, query results    |\n",
            "| **Analogy**      | The conductor of an orchestra                  | The detailed map of a city and its connections   |\n",
            "\n",
            "---\n",
            "\n",
            "### How They Work Together (The Synergy):\n",
            "\n",
            "This is where it gets interesting! LangChain and Graphs are often used *together* to build more powerful and accurate LLM applications:\n",
            "\n",
            "1.  **Retrieval Augmented Generation (RAG) with Knowledge Graphs:**\n",
            "    *   **Problem:** LLMs have a knowledge cutoff and can hallucinate.\n",
            "    *   **Solution:** LangChain can use a graph database as a \"tool\" or a \"retriever.\" When a user asks a question, LangChain's agent can formulate a query to the knowledge graph to retrieve highly relevant, structured facts and relationships. This retrieved information is then fed to the LLM as context, allowing it to generate more accurate and grounded responses.\n",
            "    *   **Example:** User asks, \"Who are the key people involved in the 'Project Alpha' and what are their roles?\" LangChain queries a knowledge graph (which stores project, person, and role nodes with relationships) to get precise answers, then passes them to the LLM for natural language generation.\n",
            "\n",
            "2.  **Complex Reasoning and Multi-Hop Questions:**\n",
            "    *   Graphs excel at multi-hop queries (e.g., \"What are the common interests of John's friends who work at Google?\").\n",
            "    *   LangChain can enable an LLM to break down a complex natural language question into a series of graph queries, execute them, and then synthesize the results.\n",
            "\n",
            "3.  **LLM-Powered Knowledge Graph Construction:**\n",
            "    *   LangChain can be used to build pipelines where an LLM processes unstructured text (e.g., articles, reports) and extracts entities and relationships. These extracted facts can then be used to populate or update a knowledge graph.\n",
            "\n",
            "4.  **Agent Memory and Context:**\n",
            "    *   While LangChain has its own memory, a knowledge graph could serve as a more structured, long-term memory for an agent, storing user preferences, past interactions, or domain-specific facts that the agent needs to recall over time.\n",
            "\n",
            "In essence, **LangChain provides the \"brain\" and \"nervous system\" for an LLM application, while a Graph provides the \"structured knowledge base\" or \"long-term memory\" that the brain can access and reason over.** They are not alternatives, but rather powerful complements.\n",
            "\n",
            "You: \n",
            "AI: That's an excellent question because while they are very different, they often complement each other in advanced AI applications.\n",
            "\n",
            "Let's break down LangChain and \"Graph\" (which I'll interpret as **Graph Databases** or **Knowledge Graphs**, as that's the most common context for this comparison).\n",
            "\n",
            "---\n",
            "\n",
            "### 1. LangChain: The Orchestration Framework for LLM Applications\n",
            "\n",
            "*   **What it is:** LangChain is an open-source **framework or library** designed to help developers build applications powered by Large Language Models (LLMs). It's not an LLM itself, nor is it a database.\n",
            "*   **What it does:** It provides tools and abstractions to:\n",
            "    *   **Chain together LLMs:** Combine multiple LLM calls or other components (like a search engine, a calculator, or a database query) into a sequence.\n",
            "    *   **Connect LLMs to external data:** Allow LLMs to interact with your own data sources (e.g., documents, databases, APIs) for retrieval-augmented generation (RAG).\n",
            "    *   **Enable LLMs to interact with their environment:** Give LLMs \"tools\" to perform actions (e.g., search the web, run code, query a database).\n",
            "    *   **Manage conversation history (Memory):** Keep track of past interactions to maintain context.\n",
            "    *   **Build Agents:** Create LLM-powered agents that can decide which actions to take based on user input.\n",
            "*   **Primary Goal:** To simplify the development of complex, context-aware, and interactive applications that leverage the power of LLMs. It's about **orchestration and application logic**.\n",
            "\n",
            "---\n",
            "\n",
            "### 2. Graph (Graph Databases / Knowledge Graphs): The Data Structure for Relationships\n",
            "\n",
            "*   **What it is:** A \"Graph\" in this context refers to a **data structure and a type of database** (a Graph Database) that stores data in terms of **nodes** (entities) and **edges** (relationships between those entities). A **Knowledge Graph** is a specific type of graph that represents real-world entities and their relationships in a structured, machine-readable format.\n",
            "*   **What it does:**\n",
            "    *   **Models complex relationships:** Excellent for representing highly interconnected data where the relationships themselves are as important as the data points (e.g., social networks, supply chains, biological pathways, organizational structures).\n",
            "    *   **Efficiently traverses connections:** Allows for very fast queries that involve navigating many relationships (e.g., \"Find all friends of friends who live in New York and work at Google\").\n",
            "    *   **Enables sophisticated reasoning:** By explicitly defining relationships, graphs can support complex inferencing and pattern discovery.\n",
            "    *   **Provides structured knowledge:** A knowledge graph acts as a structured repository of facts and their connections, making it easier for machines (and LLMs) to understand and reason about information.\n",
            "*   **Primary Goal:** To store, manage, and query highly interconnected data, emphasizing the relationships between data points. It's about **data representation and storage**.\n",
            "\n",
            "---\n",
            "\n",
            "### Key Differences Summarized:\n",
            "\n",
            "| Feature          | LangChain                                      | Graph (Database/Knowledge Graph)                 |\n",
            "| :--------------- | :--------------------------------------------- | :----------------------------------------------- |\n",
            "| **Category**     | LLM Application Framework / Orchestration Tool | Data Model / Database Type                       |\n",
            "| **Primary Role** | Building and running LLM-powered applications  | Storing and querying interconnected data         |\n",
            "| **Focus**        | Application logic, LLM interaction, workflows  | Relationships, entities, structured knowledge    |\n",
            "| **Components**   | Chains, Agents, Tools, Prompts, Memory         | Nodes, Edges, Properties                         |\n",
            "| **Output**       | LLM responses, actions, application flow       | Structured data, relationships, query results    |\n",
            "| **Analogy**      | The conductor of an orchestra                  | The detailed map of a city and its connections   |\n",
            "\n",
            "---\n",
            "\n",
            "### How They Work Together (The Synergy):\n",
            "\n",
            "This is where it gets interesting! LangChain and Graphs are often used *together* to build more powerful and accurate LLM applications:\n",
            "\n",
            "1.  **Retrieval Augmented Generation (RAG) with Knowledge Graphs:**\n",
            "    *   **Problem:** LLMs have a knowledge cutoff and can hallucinate.\n",
            "    *   **Solution:** LangChain can use a graph database as a \"tool\" or a \"retriever.\" When a user asks a question, LangChain's agent can formulate a query to the knowledge graph to retrieve highly relevant, structured facts and relationships. This retrieved information is then fed to the LLM as context, allowing it to generate more accurate and grounded responses.\n",
            "    *   **Example:** User asks, \"Who are the key people involved in the 'Project Alpha' and what are their roles?\" LangChain queries a knowledge graph (which stores project, person, and role nodes with relationships) to get precise answers, then passes them to the LLM for natural language generation.\n",
            "\n",
            "2.  **Complex Reasoning and Multi-Hop Questions:**\n",
            "    *   Graphs excel at multi-hop queries (e.g., \"What are the common interests of John's friends who work at Google?\").\n",
            "    *   LangChain can enable an LLM to break down a complex natural language question into a series of graph queries, execute them, and then synthesize the results.\n",
            "\n",
            "3.  **LLM-Powered Knowledge Graph Construction:**\n",
            "    *   LangChain can be used to build pipelines where an LLM processes unstructured text (e.g., articles, reports) and extracts entities and relationships. These extracted facts can then be used to populate or update a knowledge graph.\n",
            "\n",
            "4.  **Agent Memory and Context:**\n",
            "    *   While LangChain has its own memory, a knowledge graph could serve as a more structured, long-term memory for an agent, storing user preferences, past interactions, or domain-specific facts that the agent needs to recall over time.\n",
            "\n",
            "In essence, **LangChain provides the \"brain\" and \"nervous system\" for an LLM application, while a Graph provides the \"structured knowledge base\" or \"long-term memory\" that the brain can access and reason over.** They are not alternatives, but rather powerful complements.\n"
          ]
        }
      ],
      "source": [
        "# user_input = input(\"Enter a Query: \")\n",
        "# while user_input != \"exit\":\n",
        "#     result = app.invoke({\"messages\": [HumanMessage(content=user_input)]})\n",
        "#     user_input = input(\"Enter a Query: \")\n",
        "\n",
        "history= AgentState()\n",
        "history['messages']=[]\n",
        "user_input = input(\"Enter a Query: \")\n",
        "while user_input != \"e\":\n",
        "    print(f\"\\nYou: {user_input}\")\n",
        "    history[\"messages\"].append(HumanMessage(content=user_input))\n",
        "    result=app.invoke(history)\n",
        "    print(f\"AI: {result['messages'][-1].content}\")\n",
        "    user_input = input(\"Enter a Query: \")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
