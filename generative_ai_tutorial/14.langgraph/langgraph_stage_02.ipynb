{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Q_3sSXTWr9F",
        "outputId": "4f2a86a7-c744-4fef-e04a-2944955850ae"
      },
      "outputs": [],
      "source": [
        "!pip install langchain==0.3.24 -q\n",
        "!pip install langchain-openai -q\n",
        "!pip install langgraph -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOoYhsIQXm-U"
      },
      "source": [
        "### Chat Agent + Conversational Chat Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "qffIR7HHWwql"
      },
      "outputs": [],
      "source": [
        "from typing import TypedDict, List\n",
        "from langchain_core.messages import HumanMessage\n",
        "# from langchain_openai import ChatOpenAI\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "\n",
        "from typing import TypedDict, List, Union\n",
        "from langchain_core.messages import HumanMessage, AIMessage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CoSkPeWtW4GD"
      },
      "outputs": [],
      "source": [
        "# class AgentState(TypedDict):\n",
        "#     messages: List[HumanMessage]\n",
        "\n",
        "    \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "import os\n",
        "from langchain_google_genai import GoogleGenerativeAI\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 190,
      "metadata": {
        "id": "A3fnXhZ8Xc6Z"
      },
      "outputs": [],
      "source": [
        "class AgentState(TypedDict):\n",
        "    messages: List[Union[HumanMessage, AIMessage]]\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyBcUsfH8V9z9ES0SVlYRAZAY_Lp2AdO800\"\n",
        "\n",
        "llm=GoogleGenerativeAI(\n",
        "    model=\"gemini-2.5-flash\", temperature=0.1\n",
        "    )\n",
        "embedding=GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
        "\n",
        "def chatbot(state: AgentState) -> AgentState:\n",
        "    response = llm.invoke(state[\"messages\"])\n",
        "    # state[\"messages\"].append(AIMessage(content=response.content))\n",
        "    state['messages'].append(AIMessage(content=response))\n",
        "    return state\n",
        "\n",
        "workflow = StateGraph(AgentState)\n",
        "\n",
        "workflow.add_node(\"chatbot\", chatbot)\n",
        "\n",
        "workflow.add_edge(START, \"chatbot\")\n",
        "workflow.add_edge(\"chatbot\", END)\n",
        "\n",
        "app = workflow.compile()\n",
        "\n",
        "# from IPython.display import Image, display\n",
        "# display(Image(app.get_graph().draw_mermaid_png()))\n",
        "\n",
        "user_input = input(\"Enter a Query: \")\n",
        "result = app.invoke({\"messages\": [HumanMessage(content=user_input)]})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 191,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'messages': [HumanMessage(content='hi', additional_kwargs={}, response_metadata={}),\n",
              "  AIMessage(content='Hello! How can I help you today?', additional_kwargs={}, response_metadata={})]}"
            ]
          },
          "execution_count": 191,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 192,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict"
            ]
          },
          "execution_count": 192,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 193,
      "metadata": {},
      "outputs": [],
      "source": [
        "# class AgentState(TypedDict):\n",
        "#     messages: List[Union[HumanMessage, AIMessage]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 201,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HmZD6QcJXhJ5",
        "outputId": "9ea3c2da-c9ca-4e0f-ee6a-03c5e9e5a636"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "You: hi\n",
            "AI: Hello! How can I help you today?\n",
            "\n",
            "You: i am fine\n",
            "AI: That's good to hear! I'm glad you're doing well.\n",
            "\n",
            "So, how can I assist you today?\n",
            "\n",
            "You: what was my first msg?\n",
            "AI: Your first message was \"hi\".\n",
            "\n",
            "You: ??\n",
            "AI: It seems my answer might have surprised you or wasn't what you expected!\n",
            "\n",
            "When you asked \"what was my first msg?\", I was referring to the very first message you sent in **this current conversation**, which was \"hi\".\n",
            "\n",
            "As an AI, I don't retain memory of past conversations once they're over. My knowledge is limited to our current chat session.\n",
            "\n",
            "Did you mean something else, or were you perhaps expecting me to recall something from a previous interaction?\n",
            "{'messages': [HumanMessage(content='hi', additional_kwargs={}, response_metadata={}), AIMessage(content='Hello! How can I help you today?', additional_kwargs={}, response_metadata={}), HumanMessage(content='i am fine', additional_kwargs={}, response_metadata={}), AIMessage(content=\"That's good to hear! I'm glad you're doing well.\\n\\nSo, how can I assist you today?\", additional_kwargs={}, response_metadata={}), HumanMessage(content='what was my first msg?', additional_kwargs={}, response_metadata={}), AIMessage(content='Your first message was \"hi\".', additional_kwargs={}, response_metadata={}), HumanMessage(content='??', additional_kwargs={}, response_metadata={}), AIMessage(content='It seems my answer might have surprised you or wasn\\'t what you expected!\\n\\nWhen you asked \"what was my first msg?\", I was referring to the very first message you sent in **this current conversation**, which was \"hi\".\\n\\nAs an AI, I don\\'t retain memory of past conversations once they\\'re over. My knowledge is limited to our current chat session.\\n\\nDid you mean something else, or were you perhaps expecting me to recall something from a previous interaction?', additional_kwargs={}, response_metadata={})]}\n"
          ]
        }
      ],
      "source": [
        "# user_input = input(\"Enter a Query: \")\n",
        "# while user_input != \"exit\":\n",
        "#     result = app.invoke({\"messages\": [HumanMessage(content=user_input)]})\n",
        "#     user_input = input(\"Enter a Query: \")\n",
        "\n",
        "history= AgentState()\n",
        "history['messages']=[]\n",
        "user_input = input(\"Enter a Query: \")\n",
        "while user_input != \"e\":\n",
        "    history[\"messages\"].append(HumanMessage(content=user_input))\n",
        "    result=app.invoke(history)\n",
        "    print(f\"\\nYou: {user_input}\")\n",
        "    print(f\"AI: {result['messages'][-1].content}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # conversation_history.append(HumanMessage(content=user_input))\n",
        "    # result = app.invoke({\"messages\": conversation_history})\n",
        "    # conversation_history = result[\"messages\"]\n",
        "    user_input = input(\"Enter a Query: \")\n",
        "\n",
        "print(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {},
      "outputs": [],
      "source": [
        "my={}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict"
            ]
          },
          "execution_count": 146,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(my)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {},
      "outputs": [],
      "source": [
        "my['din']='owmd'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'din': 'owmd'}"
            ]
          },
          "execution_count": 148,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "my"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {},
      "outputs": [],
      "source": [
        "my['din']=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'din': 1}"
            ]
          },
          "execution_count": 150,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "my"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
