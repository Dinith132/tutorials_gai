{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKbMGDu8fldE"
      },
      "source": [
        "# **Text Splitters** in LangChain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K_bHo-_WZySl"
      },
      "outputs": [],
      "source": [
        "# Install the necessary packages\n",
        "!pip install langchain -qU\n",
        "!pip install langchain-community -qU\n",
        "!pip install unstructured -qU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1eiTJJPyaOFu",
        "outputId": "a89bbaed-14cd-4c17-c6b6-3d9e21449ca6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
            "libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------------------------\n",
            "LangChain is a robust framework designed to facilitate the creation of applications leveraging large language models (LLMs). By providing a suite of tools and utilities, LangChain simplifies the process of integrating LLMs into various applications, enabling developers to build sophisticated AI-powered solutions with greater ease. Its capabilities span from natural language understanding and generation to complex data processing tasks, making it a versatile choice for developing chatbots, virtual assistants, and other AI-driven applications.\n",
            "\n",
            "One of the core features of LangChain is its modular architecture, which allows developers to customize and extend the framework according to their specific needs. This modularity ensures that different components, such as model training, data preprocessing, and inference, can be independently developed and optimized. Additionally, LangChain supports seamless integration with popular machine learning libraries and frameworks, providing a comprehensive ecosystem for end-to-end development of language-based applications.\n",
            "\n",
            "LangChain also emphasizes the importance of scalability and performance. It includes optimized pipelines and efficient data handling mechanisms that can process large datasets and deliver real-time responses. This focus on performance makes it suitable for deploying applications in production environments where speed and reliability are critical.\n",
            "\n",
            "Moreover, LangChain is designed with usability in mind. It offers extensive documentation, tutorials, and community support to help developers of all skill levels get started. Whether you are an experienced machine learning engineer or a beginner in the field, LangChain provides the resources and tools needed to build effective language-driven applications.\n",
            "{'source': 'D:\\\\Next\\\\gai\\\\tutorials\\\\generative_ai_tutorial\\\\04.text_splitters\\\\data\\\\text1.txt'}\n",
            "------------------------\n",
            "CodePRO LK is an educational platform offering a wide range of online courses primarily focused on programming and machine learning. All courses are provided for free and are delivered in Sinhala, catering specifically to the Sri Lankan audience. The platform includes various learning materials such as videos, quizzes, and assignments to enhance the learning experience​​.\n",
            "\n",
            "Some of the featured courses on CodePRO LK include \"Python GUI – Tkinter,\" \"Machine Learning Project – Sentiment Analysis,\" and \"Data Structures and Algorithms.\" These courses range from beginner to intermediate levels, making them accessible to a broad spectrum of learners​.\n",
            "\n",
            "In addition to the courses, CodePRO LK also offers projects and resources to support learners in applying their knowledge practically. The platform emphasizes providing high-quality education to empower the next generation of Sri Lankans in the tech field​​.\n",
            "{'source': 'D:\\\\Next\\\\gai\\\\tutorials\\\\generative_ai_tutorial\\\\04.text_splitters\\\\data\\\\text2.txt'}\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.document_loaders import DirectoryLoader\n",
        "\n",
        "# Initialize the DirectoryLoader with the path to the directory for text files\n",
        "loader = DirectoryLoader(\"D:\\\\Next\\\\gai\\\\tutorials\\\\generative_ai_tutorial\\\\04.text_splitters\\\\data\", glob=\"**/*.txt\")\n",
        "\n",
        "# Load the text data from the directory\n",
        "dataset = loader.load()\n",
        "\n",
        "for data in dataset:\n",
        "  print(\"------------------------\")\n",
        "  print(data.page_content)\n",
        "  print(data.metadata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25W5Vrz6gs3n",
        "outputId": "4b35375f-38cf-488f-ed44-af09391d4812"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1784, 912]\n"
          ]
        }
      ],
      "source": [
        "# Calculate the token count of each document in the dataset using a character level tokenizer\n",
        "token_counts = [len(data.page_content) for data in dataset]\n",
        "\n",
        "print(token_counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y35-uTrqj6AG"
      },
      "source": [
        "### Calculate Token Count Using tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.53.0-py3-none-any.whl.metadata (39 kB)\n",
            "Collecting filelock (from transformers)\n",
            "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting huggingface-hub<1.0,>=0.30.0 (from transformers)\n",
            "  Downloading huggingface_hub-0.33.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\dinit\\.pyenv\\pyenv-win\\versions\\3.11.5\\lib\\site-packages (from transformers) (2.1.3)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\dinit\\.pyenv\\pyenv-win\\versions\\3.11.5\\lib\\site-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\dinit\\.pyenv\\pyenv-win\\versions\\3.11.5\\lib\\site-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\dinit\\.pyenv\\pyenv-win\\versions\\3.11.5\\lib\\site-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in c:\\users\\dinit\\.pyenv\\pyenv-win\\versions\\3.11.5\\lib\\site-packages (from transformers) (2.32.3)\n",
            "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
            "  Downloading tokenizers-0.21.2-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
            "Collecting safetensors>=0.4.3 (from transformers)\n",
            "  Downloading safetensors-0.5.3-cp38-abi3-win_amd64.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: tqdm>=4.27 in c:\\users\\dinit\\.pyenv\\pyenv-win\\versions\\3.11.5\\lib\\site-packages (from transformers) (4.67.1)\n",
            "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.30.0->transformers)\n",
            "  Downloading fsspec-2025.5.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\dinit\\.pyenv\\pyenv-win\\versions\\3.11.5\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: colorama in c:\\users\\dinit\\.pyenv\\pyenv-win\\versions\\3.11.5\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dinit\\.pyenv\\pyenv-win\\versions\\3.11.5\\lib\\site-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dinit\\.pyenv\\pyenv-win\\versions\\3.11.5\\lib\\site-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dinit\\.pyenv\\pyenv-win\\versions\\3.11.5\\lib\\site-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dinit\\.pyenv\\pyenv-win\\versions\\3.11.5\\lib\\site-packages (from requests->transformers) (2025.1.31)\n",
            "Downloading transformers-4.53.0-py3-none-any.whl (10.8 MB)\n",
            "   ---------------------------------------- 0.0/10.8 MB ? eta -:--:--\n",
            "    --------------------------------------- 0.3/10.8 MB ? eta -:--:--\n",
            "   -- ------------------------------------- 0.8/10.8 MB 2.2 MB/s eta 0:00:05\n",
            "   ---- ----------------------------------- 1.3/10.8 MB 2.4 MB/s eta 0:00:04\n",
            "   ----- ---------------------------------- 1.6/10.8 MB 2.2 MB/s eta 0:00:05\n",
            "   ------- -------------------------------- 2.1/10.8 MB 2.3 MB/s eta 0:00:04\n",
            "   --------- ------------------------------ 2.6/10.8 MB 2.4 MB/s eta 0:00:04\n",
            "   ----------- ---------------------------- 3.1/10.8 MB 2.3 MB/s eta 0:00:04\n",
            "   ------------- -------------------------- 3.7/10.8 MB 2.3 MB/s eta 0:00:04\n",
            "   --------------- ------------------------ 4.2/10.8 MB 2.4 MB/s eta 0:00:03\n",
            "   ----------------- ---------------------- 4.7/10.8 MB 2.4 MB/s eta 0:00:03\n",
            "   ------------------- -------------------- 5.2/10.8 MB 2.5 MB/s eta 0:00:03\n",
            "   --------------------- ------------------ 5.8/10.8 MB 2.4 MB/s eta 0:00:03\n",
            "   ---------------------- ----------------- 6.0/10.8 MB 2.4 MB/s eta 0:00:03\n",
            "   ----------------------- ---------------- 6.3/10.8 MB 2.3 MB/s eta 0:00:02\n",
            "   ------------------------- -------------- 6.8/10.8 MB 2.3 MB/s eta 0:00:02\n",
            "   --------------------------- ------------ 7.3/10.8 MB 2.3 MB/s eta 0:00:02\n",
            "   --------------------------- ------------ 7.3/10.8 MB 2.3 MB/s eta 0:00:02\n",
            "   --------------------------- ------------ 7.3/10.8 MB 2.3 MB/s eta 0:00:02\n",
            "   --------------------------- ------------ 7.3/10.8 MB 2.3 MB/s eta 0:00:02\n",
            "   --------------------------- ------------ 7.3/10.8 MB 2.3 MB/s eta 0:00:02\n",
            "   --------------------------- ------------ 7.3/10.8 MB 2.3 MB/s eta 0:00:02\n",
            "   --------------------------- ------------ 7.3/10.8 MB 2.3 MB/s eta 0:00:02\n",
            "   ---------------------------- ----------- 7.6/10.8 MB 1.6 MB/s eta 0:00:03\n",
            "   ------------------------------- -------- 8.7/10.8 MB 1.7 MB/s eta 0:00:02\n",
            "   -------------------------------- ------- 8.9/10.8 MB 1.7 MB/s eta 0:00:02\n",
            "   -------------------------------- ------- 8.9/10.8 MB 1.7 MB/s eta 0:00:02\n",
            "   --------------------------------- ------ 9.2/10.8 MB 1.6 MB/s eta 0:00:02\n",
            "   --------------------------------- ------ 9.2/10.8 MB 1.6 MB/s eta 0:00:02\n",
            "   ----------------------------------- ---- 9.7/10.8 MB 1.6 MB/s eta 0:00:01\n",
            "   ------------------------------------ --- 10.0/10.8 MB 1.6 MB/s eta 0:00:01\n",
            "   ------------------------------------ --- 10.0/10.8 MB 1.6 MB/s eta 0:00:01\n",
            "   ------------------------------------- -- 10.2/10.8 MB 1.6 MB/s eta 0:00:01\n",
            "   ------------------------------------- -- 10.2/10.8 MB 1.6 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 10.5/10.8 MB 1.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------  10.7/10.8 MB 1.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 10.8/10.8 MB 1.5 MB/s eta 0:00:00\n",
            "Downloading huggingface_hub-0.33.1-py3-none-any.whl (515 kB)\n",
            "Downloading tokenizers-0.21.2-cp39-abi3-win_amd64.whl (2.5 MB)\n",
            "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
            "   ---- ----------------------------------- 0.3/2.5 MB ? eta -:--:--\n",
            "   -------- ------------------------------- 0.5/2.5 MB 1.4 MB/s eta 0:00:02\n",
            "   ------------ --------------------------- 0.8/2.5 MB 1.5 MB/s eta 0:00:02\n",
            "   ------------ --------------------------- 0.8/2.5 MB 1.5 MB/s eta 0:00:02\n",
            "   ---------------- ----------------------- 1.0/2.5 MB 1.1 MB/s eta 0:00:02\n",
            "   -------------------- ------------------- 1.3/2.5 MB 1.0 MB/s eta 0:00:02\n",
            "   -------------------- ------------------- 1.3/2.5 MB 1.0 MB/s eta 0:00:02\n",
            "   ------------------------- -------------- 1.6/2.5 MB 943.0 kB/s eta 0:00:01\n",
            "   ----------------------------- ---------- 1.8/2.5 MB 940.7 kB/s eta 0:00:01\n",
            "   --------------------------------- ------ 2.1/2.5 MB 987.1 kB/s eta 0:00:01\n",
            "   ------------------------------------- -- 2.4/2.5 MB 986.9 kB/s eta 0:00:01\n",
            "   ---------------------------------------- 2.5/2.5 MB 965.5 kB/s eta 0:00:00\n",
            "Downloading fsspec-2025.5.1-py3-none-any.whl (199 kB)\n",
            "Downloading safetensors-0.5.3-cp38-abi3-win_amd64.whl (308 kB)\n",
            "Downloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
            "Installing collected packages: safetensors, fsspec, filelock, huggingface-hub, tokenizers, transformers\n",
            "\n",
            "   ------ --------------------------------- 1/6 [fsspec]\n",
            "   ------ --------------------------------- 1/6 [fsspec]\n",
            "   -------------------- ------------------- 3/6 [huggingface-hub]\n",
            "   -------------------- ------------------- 3/6 [huggingface-hub]\n",
            "   -------------------- ------------------- 3/6 [huggingface-hub]\n",
            "   -------------------- ------------------- 3/6 [huggingface-hub]\n",
            "   -------------------------- ------------- 4/6 [tokenizers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   --------------------------------- ------ 5/6 [transformers]\n",
            "   ---------------------------------------- 6/6 [transformers]\n",
            "\n",
            "Successfully installed filelock-3.18.0 fsspec-2025.5.1 huggingface-hub-0.33.1 safetensors-0.5.3 tokenizers-0.21.2 transformers-4.53.0\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  WARNING: The scripts huggingface-cli.exe and tiny-agents.exe are installed in 'c:\\Users\\dinit\\.pyenv\\pyenv-win\\versions\\3.11.5\\Scripts' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
            "  WARNING: The scripts transformers-cli.exe and transformers.exe are installed in 'c:\\Users\\dinit\\.pyenv\\pyenv-win\\versions\\3.11.5\\Scripts' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
          ]
        }
      ],
      "source": [
        "pip install transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "gi9MBKpdfzSZ"
      },
      "outputs": [],
      "source": [
        "# Install the tiktoken package for tokenization\n",
        "!pip install tiktoken -qU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "ename": "OSError",
          "evalue": "You are trying to access a gated repo.\nMake sure to have access to it at https://huggingface.co/google/gemma-7b.\n401 Client Error. (Request ID: Root=1-68608510-5357e3766df1a4e8266ee169;2d3f1802-ac4c-4152-a8d6-5f7312cd0b07)\n\nCannot access gated repo for url https://huggingface.co/google/gemma-7b/resolve/main/config.json.\nAccess to model google/gemma-7b is restricted. You must have access to it and be authenticated to access it. Please log in.",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dinit\\.pyenv\\pyenv-win\\versions\\3.11.5\\Lib\\site-packages\\huggingface_hub\\utils\\_http.py:409\u001b[39m, in \u001b[36mhf_raise_for_status\u001b[39m\u001b[34m(response, endpoint_name)\u001b[39m\n\u001b[32m    408\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m409\u001b[39m     \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    410\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dinit\\.pyenv\\pyenv-win\\versions\\3.11.5\\Lib\\site-packages\\requests\\models.py:1024\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1023\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[32m-> \u001b[39m\u001b[32m1024\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response=\u001b[38;5;28mself\u001b[39m)\n",
            "\u001b[31mHTTPError\u001b[39m: 401 Client Error: Unauthorized for url: https://huggingface.co/google/gemma-7b/resolve/main/config.json",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[31mGatedRepoError\u001b[39m                            Traceback (most recent call last)",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dinit\\.pyenv\\pyenv-win\\versions\\3.11.5\\Lib\\site-packages\\transformers\\utils\\hub.py:470\u001b[39m, in \u001b[36mcached_files\u001b[39m\u001b[34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[39m\n\u001b[32m    468\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(full_filenames) == \u001b[32m1\u001b[39m:\n\u001b[32m    469\u001b[39m     \u001b[38;5;66;03m# This is slightly better for only 1 file\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m470\u001b[39m     \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    471\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    472\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    473\u001b[39m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    474\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    475\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    476\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    477\u001b[39m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    478\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    479\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    482\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dinit\\.pyenv\\pyenv-win\\versions\\3.11.5\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    112\u001b[39m     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[34m__name__\u001b[39m, has_token=has_token, kwargs=kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dinit\\.pyenv\\pyenv-win\\versions\\3.11.5\\Lib\\site-packages\\huggingface_hub\\file_download.py:1008\u001b[39m, in \u001b[36mhf_hub_download\u001b[39m\u001b[34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[39m\n\u001b[32m   1007\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1008\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[32m   1010\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[32m   1012\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1014\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[32m   1017\u001b[39m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1018\u001b[39m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1019\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1020\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1021\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1022\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[32m   1023\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1024\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1025\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dinit\\.pyenv\\pyenv-win\\versions\\3.11.5\\Lib\\site-packages\\huggingface_hub\\file_download.py:1115\u001b[39m, in \u001b[36m_hf_hub_download_to_cache_dir\u001b[39m\u001b[34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[39m\n\u001b[32m   1114\u001b[39m     \u001b[38;5;66;03m# Otherwise, raise appropriate error\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1115\u001b[39m     \u001b[43m_raise_on_head_call_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead_call_error\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1117\u001b[39m \u001b[38;5;66;03m# From now on, etag, commit_hash, url and size are not None.\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dinit\\.pyenv\\pyenv-win\\versions\\3.11.5\\Lib\\site-packages\\huggingface_hub\\file_download.py:1645\u001b[39m, in \u001b[36m_raise_on_head_call_error\u001b[39m\u001b[34m(head_call_error, force_download, local_files_only)\u001b[39m\n\u001b[32m   1640\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(head_call_error, (RepositoryNotFoundError, GatedRepoError)) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1641\u001b[39m     \u001b[38;5;28misinstance\u001b[39m(head_call_error, HfHubHTTPError) \u001b[38;5;129;01mand\u001b[39;00m head_call_error.response.status_code == \u001b[32m401\u001b[39m\n\u001b[32m   1642\u001b[39m ):\n\u001b[32m   1643\u001b[39m     \u001b[38;5;66;03m# Repo not found or gated => let's raise the actual error\u001b[39;00m\n\u001b[32m   1644\u001b[39m     \u001b[38;5;66;03m# Unauthorized => likely a token issue => let's raise the actual error\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1645\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m head_call_error\n\u001b[32m   1646\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1647\u001b[39m     \u001b[38;5;66;03m# Otherwise: most likely a connection issue or Hub downtime => let's warn the user\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dinit\\.pyenv\\pyenv-win\\versions\\3.11.5\\Lib\\site-packages\\huggingface_hub\\file_download.py:1533\u001b[39m, in \u001b[36m_get_metadata_or_catch_error\u001b[39m\u001b[34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[39m\n\u001b[32m   1532\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1533\u001b[39m     metadata = \u001b[43mget_hf_file_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1534\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\n\u001b[32m   1535\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1536\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dinit\\.pyenv\\pyenv-win\\versions\\3.11.5\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    112\u001b[39m     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[34m__name__\u001b[39m, has_token=has_token, kwargs=kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dinit\\.pyenv\\pyenv-win\\versions\\3.11.5\\Lib\\site-packages\\huggingface_hub\\file_download.py:1450\u001b[39m, in \u001b[36mget_hf_file_metadata\u001b[39m\u001b[34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001b[39m\n\u001b[32m   1449\u001b[39m \u001b[38;5;66;03m# Retrieve metadata\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1450\u001b[39m r = \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1451\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mHEAD\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1452\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1453\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1454\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1455\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1456\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1457\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1458\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1459\u001b[39m hf_raise_for_status(r)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dinit\\.pyenv\\pyenv-win\\versions\\3.11.5\\Lib\\site-packages\\huggingface_hub\\file_download.py:286\u001b[39m, in \u001b[36m_request_wrapper\u001b[39m\u001b[34m(method, url, follow_relative_redirects, **params)\u001b[39m\n\u001b[32m    285\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m follow_relative_redirects:\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m     response = \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    287\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    288\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    289\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    290\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    291\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    293\u001b[39m     \u001b[38;5;66;03m# If redirection, we redirect only relative paths.\u001b[39;00m\n\u001b[32m    294\u001b[39m     \u001b[38;5;66;03m# This is useful in case of a renamed repository.\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dinit\\.pyenv\\pyenv-win\\versions\\3.11.5\\Lib\\site-packages\\huggingface_hub\\file_download.py:310\u001b[39m, in \u001b[36m_request_wrapper\u001b[39m\u001b[34m(method, url, follow_relative_redirects, **params)\u001b[39m\n\u001b[32m    309\u001b[39m response = http_backoff(method=method, url=url, **params, retry_on_exceptions=(), retry_on_status_codes=(\u001b[32m429\u001b[39m,))\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dinit\\.pyenv\\pyenv-win\\versions\\3.11.5\\Lib\\site-packages\\huggingface_hub\\utils\\_http.py:426\u001b[39m, in \u001b[36mhf_raise_for_status\u001b[39m\u001b[34m(response, endpoint_name)\u001b[39m\n\u001b[32m    423\u001b[39m     message = (\n\u001b[32m    424\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse.status_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m Client Error.\u001b[39m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCannot access gated repo for url \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse.url\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    425\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m426\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m _format(GatedRepoError, message, response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    428\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m error_message == \u001b[33m\"\u001b[39m\u001b[33mAccess to this resource is disabled.\u001b[39m\u001b[33m\"\u001b[39m:\n",
            "\u001b[31mGatedRepoError\u001b[39m: 401 Client Error. (Request ID: Root=1-68608510-5357e3766df1a4e8266ee169;2d3f1802-ac4c-4152-a8d6-5f7312cd0b07)\n\nCannot access gated repo for url https://huggingface.co/google/gemma-7b/resolve/main/config.json.\nAccess to model google/gemma-7b is restricted. You must have access to it and be authenticated to access it. Please log in.",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m tokenizer = \u001b[43mAutoTokenizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgoogle/gemma-7b\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dinit\\.pyenv\\pyenv-win\\versions\\3.11.5\\Lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:1002\u001b[39m, in \u001b[36mAutoTokenizer.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[39m\n\u001b[32m   1000\u001b[39m         config = AutoConfig.for_model(**config_dict)\n\u001b[32m   1001\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1002\u001b[39m         config = \u001b[43mAutoConfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1003\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1004\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1005\u001b[39m config_tokenizer_class = config.tokenizer_class\n\u001b[32m   1006\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(config, \u001b[33m\"\u001b[39m\u001b[33mauto_map\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mAutoTokenizer\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config.auto_map:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dinit\\.pyenv\\pyenv-win\\versions\\3.11.5\\Lib\\site-packages\\transformers\\models\\auto\\configuration_auto.py:1197\u001b[39m, in \u001b[36mAutoConfig.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[39m\n\u001b[32m   1194\u001b[39m trust_remote_code = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mtrust_remote_code\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m   1195\u001b[39m code_revision = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mcode_revision\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m1197\u001b[39m config_dict, unused_kwargs = \u001b[43mPretrainedConfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_config_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1198\u001b[39m has_remote_code = \u001b[33m\"\u001b[39m\u001b[33mauto_map\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mAutoConfig\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict[\u001b[33m\"\u001b[39m\u001b[33mauto_map\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1199\u001b[39m has_local_code = \u001b[33m\"\u001b[39m\u001b[33mmodel_type\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m config_dict[\u001b[33m\"\u001b[39m\u001b[33mmodel_type\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m CONFIG_MAPPING\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dinit\\.pyenv\\pyenv-win\\versions\\3.11.5\\Lib\\site-packages\\transformers\\configuration_utils.py:608\u001b[39m, in \u001b[36mPretrainedConfig.get_config_dict\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[39m\n\u001b[32m    606\u001b[39m original_kwargs = copy.deepcopy(kwargs)\n\u001b[32m    607\u001b[39m \u001b[38;5;66;03m# Get config dict associated with the base config file\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m608\u001b[39m config_dict, kwargs = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_config_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    609\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m config_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    610\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {}, kwargs\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dinit\\.pyenv\\pyenv-win\\versions\\3.11.5\\Lib\\site-packages\\transformers\\configuration_utils.py:667\u001b[39m, in \u001b[36mPretrainedConfig._get_config_dict\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[39m\n\u001b[32m    663\u001b[39m configuration_file = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33m_configuration_file\u001b[39m\u001b[33m\"\u001b[39m, CONFIG_NAME) \u001b[38;5;28;01mif\u001b[39;00m gguf_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m gguf_file\n\u001b[32m    665\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    666\u001b[39m     \u001b[38;5;66;03m# Load from local folder or from cache or download from model Hub and cache\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m667\u001b[39m     resolved_config_file = \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    669\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfiguration_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    680\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    681\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m resolved_config_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    682\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, kwargs\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dinit\\.pyenv\\pyenv-win\\versions\\3.11.5\\Lib\\site-packages\\transformers\\utils\\hub.py:312\u001b[39m, in \u001b[36mcached_file\u001b[39m\u001b[34m(path_or_repo_id, filename, **kwargs)\u001b[39m\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcached_file\u001b[39m(\n\u001b[32m    255\u001b[39m     path_or_repo_id: Union[\u001b[38;5;28mstr\u001b[39m, os.PathLike],\n\u001b[32m    256\u001b[39m     filename: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m    257\u001b[39m     **kwargs,\n\u001b[32m    258\u001b[39m ) -> Optional[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m    259\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    260\u001b[39m \u001b[33;03m    Tries to locate a file in a local folder and repo, downloads and cache it if necessary.\u001b[39;00m\n\u001b[32m    261\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    310\u001b[39m \u001b[33;03m    ```\u001b[39;00m\n\u001b[32m    311\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m312\u001b[39m     file = \u001b[43mcached_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    313\u001b[39m     file = file[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m file\n\u001b[32m    314\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m file\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dinit\\.pyenv\\pyenv-win\\versions\\3.11.5\\Lib\\site-packages\\transformers\\utils\\hub.py:533\u001b[39m, in \u001b[36mcached_files\u001b[39m\u001b[34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[39m\n\u001b[32m    531\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _raise_exceptions_for_gated_repo:\n\u001b[32m    532\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m533\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[32m    534\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mYou are trying to access a gated repo.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mMake sure to have access to it at \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    535\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    536\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    537\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, LocalEntryNotFoundError):\n\u001b[32m    538\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _raise_exceptions_for_connection_errors:\n",
            "\u001b[31mOSError\u001b[39m: You are trying to access a gated repo.\nMake sure to have access to it at https://huggingface.co/google/gemma-7b.\n401 Client Error. (Request ID: Root=1-68608510-5357e3766df1a4e8266ee169;2d3f1802-ac4c-4152-a8d6-5f7312cd0b07)\n\nCannot access gated repo for url https://huggingface.co/google/gemma-7b/resolve/main/config.json.\nAccess to model google/gemma-7b is restricted. You must have access to it and be authenticated to access it. Please log in."
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-7b\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BhN39pFKX4cl",
        "outputId": "c94c07a1-ceb1-499a-a2cb-04541aefc0a9"
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "'Could not automatically map gemini-2.5-flash to a tokeniser. Please use `tiktoken.get_encoding` to explicitly get the tokeniser you expect.'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtiktoken\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m tokenizer_model = \u001b[43mtiktoken\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding_for_model\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mgemini-2.5-flash\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(tokenizer_model)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dinit\\.pyenv\\pyenv-win\\versions\\3.11.5\\Lib\\site-packages\\tiktoken\\model.py:110\u001b[39m, in \u001b[36mencoding_for_model\u001b[39m\u001b[34m(model_name)\u001b[39m\n\u001b[32m    105\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mencoding_for_model\u001b[39m(model_name: \u001b[38;5;28mstr\u001b[39m) -> Encoding:\n\u001b[32m    106\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Returns the encoding used by a model.\u001b[39;00m\n\u001b[32m    107\u001b[39m \n\u001b[32m    108\u001b[39m \u001b[33;03m    Raises a KeyError if the model name is not recognised.\u001b[39;00m\n\u001b[32m    109\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m110\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m get_encoding(\u001b[43mencoding_name_for_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dinit\\.pyenv\\pyenv-win\\versions\\3.11.5\\Lib\\site-packages\\tiktoken\\model.py:97\u001b[39m, in \u001b[36mencoding_name_for_model\u001b[39m\u001b[34m(model_name)\u001b[39m\n\u001b[32m     94\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m model_encoding_name\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m encoding_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[32m     98\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCould not automatically map \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m to a tokeniser. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     99\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPlease use `tiktoken.get_encoding` to explicitly get the tokeniser you expect.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    100\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m encoding_name\n",
            "\u001b[31mKeyError\u001b[39m: 'Could not automatically map gemini-2.5-flash to a tokeniser. Please use `tiktoken.get_encoding` to explicitly get the tokeniser you expect.'"
          ]
        }
      ],
      "source": [
        "import tiktoken\n",
        "\n",
        "tokenizer_model = tiktoken.encoding_for_model('gemini-2.5-flash')\n",
        "print(tokenizer_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "bodTZ2HZahSe"
      },
      "outputs": [],
      "source": [
        "# Get the encoding for the tokenizer\n",
        "tokenizer = tiktoken.get_encoding('cl100k_base')\n",
        "\n",
        "# Create a function to calculate the length of text in tokens using tiktoken\n",
        "def tiktoken_len(text):\n",
        "    tokens = tokenizer.encode(text)\n",
        "    token_length = len(tokens)\n",
        "    return token_length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLOCX6unheJQ",
        "outputId": "51f3e7ae-4be4-4c4a-fa8b-ba486c92f30f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[286, 168]\n"
          ]
        }
      ],
      "source": [
        "# Calculate the token count of each document in the dataset using tiktoken\n",
        "token_counts = [tiktoken_len(data.page_content) for data in dataset]\n",
        "\n",
        "print(token_counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8S2Hw7QTbRxG"
      },
      "source": [
        "### Chunking the Text Using **RecursiveCharacterTextSplitter**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "XOOZ2YLTYLvN"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "# Initialize the text splitter with a chunk size of 150 and no overlap, using character length function\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=150,\n",
        "    chunk_overlap=0,\n",
        "    length_function=len,\n",
        "    separators=['\\n\\n', '\\n', ' ', '']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3SGbfsBObb2p",
        "outputId": "c3730a7f-7c77-40e8-9b75-0e58d0e539d6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Split the text of the second document in the dataset into chunks\n",
        "chunks = text_splitter.split_text(dataset[1].page_content)\n",
        "\n",
        "len(chunks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEpQuIRGYT6V",
        "outputId": "9acfa266-6476-4a16-b1ab-5e67de613f2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CodePRO LK is an educational platform offering a wide range of online courses primarily focused on programming and machine learning. All courses are\n",
            "148\n",
            "provided for free and are delivered in Sinhala, catering specifically to the Sri Lankan audience. The platform includes various learning materials\n",
            "146\n"
          ]
        }
      ],
      "source": [
        "print(chunks[0])\n",
        "print(len(chunks[0]))\n",
        "print(chunks[1])\n",
        "print(len(chunks[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "hdDW4wTLhfu4"
      },
      "outputs": [],
      "source": [
        "# Reinitialize the text splitter with a chunk size of 150 and an overlap of 20, using character length function\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=150,\n",
        "    chunk_overlap=20,\n",
        "    length_function=len,\n",
        "    separators=['\\n\\n', '\\n', ' ', '']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yo54HHwqhk3_",
        "outputId": "e442a87c-8e4a-4eff-8e85-33d9fa35465f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Split the text of the second document in the dataset into chunks\n",
        "chunks = text_splitter.split_text(dataset[1].page_content)\n",
        "\n",
        "len(chunks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcNEzARQhmqY",
        "outputId": "105ecdcb-d6f8-42d2-b324-93a56e677f5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CodePRO LK is an educational platform offering a wide range of online courses primarily focused on programming and machine learning. All courses are\n",
            "148\n",
            "All courses are provided for free and are delivered in Sinhala, catering specifically to the Sri Lankan audience. The platform includes various\n",
            "143\n"
          ]
        }
      ],
      "source": [
        "print(chunks[0])\n",
        "print(len(chunks[0]))\n",
        "print(chunks[1])\n",
        "print(len(chunks[1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKd3hNsIk9SN"
      },
      "source": [
        "### Chunking the Text Using tiktoken Length Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "IdiSZPd_hu0Q"
      },
      "outputs": [],
      "source": [
        "# Reinitialize the text splitter with a chunk size of 150 and an overlap of 20, using tiktoken length function\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=150,\n",
        "    chunk_overlap=20,\n",
        "    length_function=tiktoken_len,\n",
        "    separators=['\\n\\n', '\\n', ' ', '']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "coRgQ9nDI-AC",
        "outputId": "523476b6-5547-427f-8189-2bbb41dccc26"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Split the text of the second document in the dataset into chunks\n",
        "chunks = text_splitter.split_text(dataset[1].page_content)\n",
        "\n",
        "len(chunks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZcoHNl_Nh_Gc",
        "outputId": "111cb7be-34a9-452c-c311-4abc43de7a58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CodePRO LK is an educational platform offering a wide range of online courses primarily focused on programming and machine learning. All courses are provided for free and are delivered in Sinhala, catering specifically to the Sri Lankan audience. The platform includes various learning materials such as videos, quizzes, and assignments to enhance the learning experience​​.\n",
            "\n",
            "Some of the featured courses on CodePRO LK include \"Python GUI – Tkinter,\" \"Machine Learning Project – Sentiment Analysis,\" and \"Data Structures and Algorithms.\" These courses range from beginner to intermediate levels, making them accessible to a broad spectrum of learners​.\n",
            "121\n",
            "In addition to the courses, CodePRO LK also offers projects and resources to support learners in applying their knowledge practically. The platform emphasizes providing high-quality education to empower the next generation of Sri Lankans in the tech field​​.\n",
            "47\n"
          ]
        }
      ],
      "source": [
        "print(chunks[0])\n",
        "print(tiktoken_len(chunks[0]))\n",
        "print(chunks[1])\n",
        "print(tiktoken_len(chunks[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
